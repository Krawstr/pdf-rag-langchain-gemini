# Emergia-RAG: Sistema de Perguntas e Respostas com IA

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Framework](https://img.shields.io/badge/Framework-LangChain-green.svg)
![LLM](https://img.shields.io/badge/LLM-Gemini_API-red.svg)
![Database](https://img.shields.io/badge/Vector_DB-ChromaDB-purple.svg)

---

## üìú √çndice

* [1. Motiva√ß√£o](#-1-motiva√ß√£o)
* [2. O que √© Emergia?](#-2-o-que-√©-emergia)
* [3. Arquitetura do Sistema (RAG)](#-3-arquitetura-do-sistema-rag)
* [4. Como Funciona](#-4-como-funciona)
    * [Etapa 1: Indexa√ß√£o de Dados (Offline)](#etapa-1-indexa√ß√£o-de-dados-offline)
    * [Etapa 2: Infer√™ncia e Gera√ß√£o (Online)](#etapa-2-infer√™ncia-e-gera√ß√£o-online)
* [5. Stack de Tecnologias](#-5-stack-de-tecnologias)
* [6. Configura√ß√£o do Ambiente](#-6-configura√ß√£o-do-ambiente)
* [7. Como Usar](#-7-como-usar)
* [8. Desafios e Solu√ß√µes](#-8-desafios-e-solu√ß√µes)
* [9. Pr√≥ximos Passos](#-9-pr√≥ximos-passos)
* [10. Agradecimentos](#-10-agradecimentos)

---

## üí° 1. Motiva√ß√£o

Tudo come√ßou com um "erro de digita√ß√£o" no meu curr√≠culo, apontado pelo meu mentor durante uma conversa. A palavra era **"emergia"**, e n√£o "energia". Expliquei que o termo estava correto e se referia a um conceito fascinante da ecologia, frequentemente desconhecido.

Essa confus√£o me inspirou a transformar a curiosidade em um projeto pr√°tico. Unindo a sugest√£o do meu mentor de explorar agentes de IA com meu interesse no tema, decidi construir um sistema focado exclusivamente em responder perguntas sobre Emergia, garantindo que as respostas fossem precisas e confi√°veis.

## üåø 2. O que √© Emergia?

**Emergia** (do ingl√™s, *emergy* ou *embodied energy*) √© um conceito da ecologia e da termodin√¢mica que se refere √† quantidade total de energia de um determinado tipo (geralmente solar) que foi utilizada, direta ou indiretamente, para gerar um produto, servi√ßo ou recurso. √â uma forma de avaliar o verdadeiro "custo" ambiental e energ√©tico de algo, considerando toda a cadeia de transforma√ß√µes na natureza e na economia.

## üèóÔ∏è 3. Arquitetura do Sistema (RAG)

Este projeto implementa o padr√£o de arquitetura **Retrieval-Augmented Generation (RAG)**. O objetivo do RAG √© aprimorar a qualidade das respostas de Modelos de Linguagem Grandes (LLMs), tornando-as mais confi√°veis e menos propensas a "alucina√ß√µes" (informa√ß√µes factualmente incorretas).

O fluxo funciona da seguinte forma:

```
Pergunta do Usu√°rio -> [1. Recupera√ß√£o de Documentos] -> [2. Inje√ß√£o de Contexto no Prompt] -> [3. Gera√ß√£o de Resposta pelo LLM] -> Resposta Final
```

Em vez de enviar a pergunta diretamente ao LLM, o sistema primeiro busca em uma base de conhecimento privada (neste caso, artigos e PDFs sobre Emergia) os trechos mais relevantes. Esses trechos s√£o ent√£o fornecidos ao LLM como um contexto, para que ele formule uma resposta baseada nos fatos apresentados.

## üõ†Ô∏è 4. Como Funciona

### Etapa 1: Indexa√ß√£o de Dados (Offline)

Esta etapa prepara a base de conhecimento que alimentar√° o sistema. √â executada uma √∫nica vez ou sempre que a base de dados for atualizada. O script respons√°vel por esta fase √© o `create_db.py`.

1.  **Carregamento de Dados (`Data Loading`)**: Documentos em formato PDF, localizados em um diret√≥rio, s√£o carregados utilizando a classe `PyPDFDirectoryLoader` do LangChain.
2.  **Segmenta√ß√£o de Documentos (`Chunking`)**: Os documentos s√£o divididos em segmentos menores (*chunks*) usando `RecursiveCharacterTextSplitter`. Esta t√©cnica, a mais recomendada, tenta manter a coes√£o sem√¢ntica do texto ao dividi-lo em separadores l√≥gicos.
3.  **Gera√ß√£o de Embeddings (`Embedding Generation`)**: Cada *chunk* de texto √© convertido em um vetor num√©rico de alta dimens√£o usando o modelo `models/embedding-001` da API do Google.
4.  **Armazenamento e Indexa√ß√£o (`Vector Storage & Indexing`)**: Os vetores de embedding, juntamente com os textos originais, s√£o armazenados em um banco de dados vetorial local, o **ChromaDB**.

### Etapa 2: Infer√™ncia e Gera√ß√£o (Online)

Esta etapa ocorre em tempo real a cada pergunta do usu√°rio e √© gerenciada pelo script `main.py`.

1.  **Consulta do Usu√°rio**: O sistema recebe uma pergunta sobre Emergia.
2.  **Vetoriza√ß√£o da Consulta**: A pergunta √© convertida em um vetor de embedding usando o mesmo modelo da Etapa 1.
3.  **Busca por Similaridade**: O sistema realiza uma busca no ChromaDB para encontrar os *k* chunks de texto mais similares √† pergunta.
4.  **Aumento do Prompt**: Os *chunks* recuperados s√£o inseridos em um template de prompt juntamente com a pergunta original, instruindo o LLM a responder com base *exclusivamente* no contexto fornecido.
5.  **Gera√ß√£o da Resposta**: O prompt aumentado √© enviado ao LLM (API do Gemini), que sintetiza uma resposta coesa e factual.

## üöÄ 5. Stack de Tecnologias

* **Linguagem**: Python
* **Orquestra√ß√£o de LLMs**: LangChain
* **Modelo de Linguagem (LLM)**: Google Gemini API
* **Modelo de Embedding**: Google `models/embedding-001`
* **Banco de Dados Vetorial**: ChromaDB
* **Manipula√ß√£o de Dados**: `PyPDFDirectoryLoader`, `RecursiveCharacterTextSplitter`

## ‚öôÔ∏è 6. Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/seu-usuario/emergia-rag.git
    cd emergia-rag
    ```

2.  **Crie e ative um ambiente virtual:**
    ```bash
    # Linux/macOS
    python3 -m venv venv
    source venv/bin/activate

    # Windows
    python -m venv venv
    .\venv\Scripts\activate
    ```

3.  **Instale as depend√™ncias:**
    (Crie um ficheiro `requirements.txt` com as bibliotecas necess√°rias, como `langchain`, `google-generativeai`, `chromadb`, `pypdf`, etc.)
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure suas credenciais:**
    Crie um ficheiro `.env` na raiz do projeto e adicione sua chave da API do Google:
    ```
    GOOGLE_API_KEY="SUA_CHAVE_API_AQUI"
    ```

## ‚ñ∂Ô∏è 7. Como Usar

1.  **Prepare a Base de Conhecimento:**
    * Crie uma pasta chamada `data` na raiz do projeto.
    * Adicione todos os seus ficheiros PDF sobre Emergia dentro desta pasta.

2.  **Execute o script de indexa√ß√£o:**
    Este script ir√° processar os PDFs, gerar os embeddings e criar o banco de dados vetorial.
    ```bash
    python create_db.py
    ```

3.  **Execute a interface de consulta:**
    Ap√≥s a cria√ß√£o do banco, execute o script principal para come√ßar a fazer perguntas.
    ```bash
    python main.py
    ```
    O terminal ir√° exibir um prompt para voc√™ digitar sua pergunta.

## üß† 8. Desafios e Solu√ß√µes

O principal desafio t√©cnico foi lidar com o limite de requisi√ß√µes da API do Google (`erro 429 Too Many Requests`) ao tentar vetorizar centenas de *chunks* de uma s√≥ vez.

**Solu√ß√£o:** Implementei um sistema de processamento em lotes (*batch processing*). Em vez de enviar todos os *chunks* de uma vez, o c√≥digo os agrupa em lotes de tamanho 100. O primeiro lote √© usado para criar o banco de dados, e os lotes subsequentes s√£o adicionados num loop. Para garantir a robustez, adicionei uma pausa de 1 segundo (`time.sleep(1)`) entre o processamento de cada lote, evitando exceder a cota de requisi√ß√µes por minuto da API.

## üéØ 9. Pr√≥ximos Passos

Este projeto foi uma excelente introdu√ß√£o √† arquitetura RAG. As melhorias planejadas incluem:

* [ ] **Aprimorar a Base de Dados**: Realizar uma curadoria mais rigorosa dos artigos e buscar mais fontes.
* [ ] **Desenvolver uma Interface Gr√°fica**: Criar uma GUI com `Tkinter` ou uma interface web com `Flask`/`Django`.
* [ ] **Refinar a Recupera√ß√£o**: Implementar t√©cnicas mais avan√ßadas de recupera√ß√£o para melhorar a qualidade do contexto.
* [ ] **Avalia√ß√£o do Sistema**: Criar um conjunto de dados de perguntas e respostas para avaliar objetivamente a performance do RAG.

## üôè 10. Agradecimentos

Um agradecimento especial ao meu mentor, cuja provoca√ß√£o inicial foi o catalisador para este projeto. O aprendizado foi imenso.

Feedbacks e contribui√ß√µes s√£o sempre bem-vindos!